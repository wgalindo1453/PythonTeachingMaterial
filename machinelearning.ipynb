{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wgalindo1453/PythonTeachingMaterial/blob/main/machinelearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 0: Overview of Today's Task\n",
        "\n",
        "This is Last lecture for Python education of JupyterVox.\n",
        "* Task 1: Review of Functions and Libraries\n",
        "* Task 2: A Simple Machine Learning Activity: We'll do a simple activity where we train a computer to do addition using machine learning. This will help you understand how computers can learn from examples.\n",
        "* Task 3: Personalized AI Tutor Bot: In this project, we will be creating a text-to-speech chatbot using OpenAI's GPT-3 and Google's Text-to-Speech (gTTS) library. The chatbot will take user's question as input, generate a response using GPT-3, convert the response to speech using gTTS, and then play the audio."
      ],
      "metadata": {
        "id": "2Mq-l_C5z9ex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Review of Functions and Libraries"
      ],
      "metadata": {
        "id": "R-I1PFbt1Onj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \"Square root\" with the math lib\n",
        "\n",
        "Ask the student to the compute the square root of 10 with the math lib."
      ],
      "metadata": {
        "id": "HlytxqtS1Yvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "math.sqrt(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTCfEHys1it3",
        "outputId": "5c370b9c-4dd6-4d79-8012-d6c7ab2b26a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.1622776601683795"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tell the students that, some times, we can do the following to avoid typing \"math.\"\n",
        "\n",
        "Basically, we tell Python to import everything from \"math\", so Python knows where the function \"sqrt\" is from.\n"
      ],
      "metadata": {
        "id": "jf9Zq0wU1m8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import * # * means every functions\n",
        "\n",
        "sqrt(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa_eo8A71vgd",
        "outputId": "dc54e9e7-8426-43fe-98c9-d677c0ede76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.1622776601683795"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Sum function\n",
        "\n",
        "Ask the student to write a function that sums two numbers."
      ],
      "metadata": {
        "id": "qsx8ocI_1wmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add(a, b):\n",
        "  r = a + b\n",
        "  return r\n",
        "\n",
        "add(5, 11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1cL-Pfp1zcF",
        "outputId": "4f1e88d8-865a-48a1-96f3-4ecba79745bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: A Simple Machine Learning Activity\n",
        "Before we dive into creating our AI tutor bot, let's do a simple activity to understand the concept of machine learning. We'll train our computer to do simple addition operations. Remember, just like how you learn from examples in school, we'll give the computer examples of addition, and it will learn from these examples."
      ],
      "metadata": {
        "id": "f1tPzoPRAjck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this activity, we're going to teach our computer to do simple addition using a basic machine learning algorithm called linear regression. Don't worry if you haven't heard of it before - it's just a fancy name for a simple idea!\n",
        "\n",
        "**Linear Regression:** In simple terms, imagine you have a scatter plot of data points on a graph, and you want to draw a straight line that fits these points as closely as possible. That's essentially what Linear Regression does. The line represents the relationship between the input variables (**in our case, the pairs of numbers**) and the output variable (**their sum**)."
      ],
      "metadata": {
        "id": "uot_gw_RAuLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we need to import some tools to help us with our activity\n",
        "import numpy as np  # By adding as np, we're giving NumPy a shorter nickname so we can call it more easily in our code.\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "# Let's create our examples - pairs of numbers and their sums\n",
        "#X' is our collection of number pairs and 'y' is the sum of those pairs.\n",
        "# So, for example, the pair [1, 2] in 'X' corresponds to the number '3' in 'y', because 1 + 2 = 3.\n",
        "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10]])\n",
        "y = np.array([3, 7, 11, 15, 19])\n",
        "\n",
        "# Now, we'll use a simple machine learning algorithm to train our computer\n",
        "model = LinearRegression()\n",
        "model.fit(X, y) #we're telling the computer to learn the pattern in our examples.\n",
        "\n",
        "# Finally, let's test our computer by asking it to add new pairs of numbers\n",
        "test_input = np.array([[2, 3], [4, 5], [6, 7]])\n",
        "predictions = model.predict(test_input)\n",
        "\n",
        "# Let's see how our computer did!\n",
        "print(\"Test input:\", test_input)\n",
        "print(\"Predicted output:\", predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYF5HcEpAs_E",
        "outputId": "2611ef7e-0189-4b41-911c-2771047c8c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test input: [[2 3]\n",
            " [4 5]\n",
            " [6 7]]\n",
            "Predicted output: [ 5.  9. 13.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Personalized ChatGPT Tutor Bot\n",
        "Remember when you trained a computer to do simple addition in our **machine learning** activity? You provided it with many examples, and the computer learned from those examples to add numbers by itself. This is the key concept behind **machine learning - learning from examples to make predictions or decisions**.\n",
        "\n",
        "Now, let's apply the same idea but with a twist. Instead of teaching the computer to add numbers, we taught it to understand and generate human-like text. This is what programmers did with ChatGPT!\n",
        "\n",
        "ChatGPT is like a super smart helper that's been **trained** on a massive library filled with thousands of books, articles, and websites. Just as you learned to add numbers from examples, ChatGPT has learned to understand and generate text from the examples it was trained on.\n",
        "\n",
        "When you ask ChatGPT a question, it uses what it's learned from its **training** to create a response. It's similar to how you would use what you've learned in your math or science class to answer a question in your homework. The more examples ChatGPT has been trained on, the better it gets at answering your questions.\n",
        "\n",
        "But, keep in mind, while ChatGPT is clever, it's not perfect. Just like you made a few mistakes when you were learning to add numbers, ChatGPT can also make mistakes. So, it's always a smart idea to double-check the answers, especially when you're doing your homework or learning something new."
      ],
      "metadata": {
        "id": "yivzkKDQ15oi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing and Importing Necessary Libraries\n",
        "Before we can start programming our ChatGPT Tutor Bot, we need to make sure we have the right tools. These tools are special pieces of code called 'libraries'. Just like in a real library, these code libraries have different sections (or 'books') that we can borrow and use in our own program.\n",
        "\n",
        "First, we install the libraries we need:\n",
        "\n",
        "* openai: This library lets us talk to the OpenAI system, which is where our ChatGPT lives.\n",
        "* gTTS: This stands for 'Google Text-to-Speech'. It's a library that can turn text into spoken words, which is really useful for our friends who have trouble seeing.\n",
        "* IPython: This is a library that helps us display things like audio files in our programming notebook.\n",
        "\n",
        "The OpenAI key for GPT-3 access is also set at this stage. Please remember to replace the placeholder with your actual OpenAI API key."
      ],
      "metadata": {
        "id": "bnW4_j4z4j8u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORO3OHzycXEn",
        "outputId": "9e518eea-ac87-4165-ef38-7ed2e8a4e715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m852.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.3.2-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.27.1)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.4)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.10/dist-packages (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from IPython) (67.7.2)\n",
            "Collecting jedi>=0.16 (from IPython)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from IPython) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from IPython) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from IPython) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from IPython) (3.0.38)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from IPython) (2.14.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from IPython) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from IPython) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from IPython) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->IPython) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->IPython) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython) (0.2.6)\n",
            "Installing collected packages: jedi\n",
            "Successfully installed jedi-0.18.2\n"
          ]
        }
      ],
      "source": [
        "# Installation of necessary libraries\n",
        "!pip install openai\n",
        "!pip install gTTS\n",
        "!pip install IPython\n",
        "\n",
        "# Importing necessary libraries\n",
        "import openai\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "import time\n",
        "\n",
        "# Setup OpenAI API key for GPT-3\n",
        "openai.api_key = 'OPENAI_API_KEY'  # Please replace this with your actual OpenAI API key"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPT-3 Response Generation\n",
        "In our function get_gpt3_response(prompt), we ask a question and get an answer from ChatGPT:\n",
        "\n",
        "* We use openai.Completion.create() to ask our question to the OpenAI system.\n",
        "* We choose the \"text-davinci-002\" engine, which is the specific version of ChatGPT we're talking to.\n",
        "* We set 'temperature' to 0.5. This tells ChatGPT to balance between focused and creative answers.\n",
        "* We limit the length of our answer with 'max_tokens=100'. This means our answer should be around 100 words or so.\n",
        "\n",
        "In summary, this function is like having a conversation with ChatGPT, where we ask a question and it gives us an answer based on its training."
      ],
      "metadata": {
        "id": "ja_6wJ4403cr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_gpt3_response(prompt):\n",
        "    response = openai.Completion.create(\n",
        "      engine=\"text-davinci-002\", #free version :)\n",
        "      prompt=prompt,\n",
        "      temperature=0.5,\n",
        "      max_tokens=100\n",
        "    )\n",
        "\n",
        "    return response.choices[0].text.strip()\n",
        "    # GPT-3 generates several possible responses (choices).\n",
        "    # Here, we select the first one (choices[0]) and get its text.\n",
        "    # The strip() method is used to remove any leading or trailing white spaces in the response.\n"
      ],
      "metadata": {
        "id": "bIb6z_5Whk_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text-to-Speech Conversion\n",
        "Next, we define a function text_to_speech(text) that takes a text input and converts it into speech using the Google Text-to-Speech (gTTS) library. The converted speech is saved as an mp3 file named 'output.mp3'"
      ],
      "metadata": {
        "id": "55q6OgVb64LA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert text to speech using gTTS\n",
        "def text_to_speech(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    tts.save('output.mp3')\n",
        "    return 'output.mp3'"
      ],
      "metadata": {
        "id": "RQ-EkyJRhpYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Chatbot Loop\n",
        "Finally, we create the main chatbot loop where the user interaction happens. In this loop, the chatbot continually prompts the user to ask a question. If the user types 'quit', the loop breaks and the program ends. Otherwise, the chatbot gets a GPT-3 generated response to the question, converts the response into speech, and plays the audio. After each response, the program waits for a moment before prompting for the next question."
      ],
      "metadata": {
        "id": "FUmjlQVj6_Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main chatbot loop\n",
        "while True:\n",
        "    # Personalize it for the students\n",
        "    # Get user's name\n",
        "    user_name = input(\"Enter your name: \")\n",
        "\n",
        "    # Greet the user\n",
        "    print(f\"Chatbot: Hi {user_name}! How can I assist you today?\")\n",
        "\n",
        "    # Get user's question\n",
        "    question = input(\"Ask a question: \")\n",
        "\n",
        "    # If user types 'quit', break the loop\n",
        "    if question.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    # Get GPT-3's response\n",
        "    gpt3_response = get_gpt3_response(question)\n",
        "    print(\"Chatbot: \", gpt3_response)\n",
        "\n",
        "    # Convert response to speech and play it\n",
        "    speech_file = text_to_speech(gpt3_response)\n",
        "    display(Audio(speech_file, autoplay=True))\n",
        "\n",
        "    time.sleep(1)  # Wait for a moment before next question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "3gde0e1dhto6",
        "outputId": "97166e0e-5f73-4566-bc6a-fe5c3ae1d32f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your name: WIlliam\n",
            "Chatbot: Hi WIlliam! How can I assist you today?\n",
            "Ask a question: What is the capital of texas?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-4575ba6f264c>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Get GPT-3's response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mgpt3_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_gpt3_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Chatbot: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpt3_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-71f5b52fcc86>\u001b[0m in \u001b[0;36mget_gpt3_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_gpt3_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     response = openai.Completion.create(\n\u001b[0m\u001b[1;32m      3\u001b[0m       \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-davinci-002\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#free version :)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    151\u001b[0m         )\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             return (\n\u001b[0;32m--> 624\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    625\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    688\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             )\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: <empty message>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FYLkg8lEz5Yi"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}