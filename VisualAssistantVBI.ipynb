{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNca7iizGS3bx47altlB3Q2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wgalindo1453/PythonTeachingMaterial/blob/main/VisualAssistantVBI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visual Assistant using ChatGPT (VBI Tutorial)**"
      ],
      "metadata": {
        "id": "nAafFA_o9oCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What This Program Does:\n",
        "\n",
        "This program is like a smart helper on your computer. It can look at your screen, figure out what's on it, and then tell you about it using speech. It also listens to your voice commands. Pretty cool, right?"
      ],
      "metadata": {
        "id": "5GufESO3-OYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Tools"
      ],
      "metadata": {
        "id": "ENQrm841-m6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyttsx3 #This is like a robot voice for your computer. pyttsx3 is a tool that allows the computer to talk to you.\n",
        "import base64 #Think of base64 as a secret code translator. When you want to send images over the internet, they need to be in a special code.\n",
        "import speech_recognition as sr  #This tool is like the computer's ears. It's used for listening to what you say.\n",
        "import keyboard #The keyboard library is all about listening to your keyboard. It helps the program know when you press a key.\n",
        "import pyautogui #This tool is like the computer's eyes and hands. pyautogui can take pictures of your screen (like a screenshot)\n",
        "from openai import OpenAI #This library contains tools and functions that allow us to communicate with OpenAI's services\n",
        "\n",
        "#Each of these tools gives the computer special abilities, like talking,\n",
        "#listening, seeing your screen, understanding keyboard presses, and sending images.\n",
        "#With these tools, you can make your computer do some pretty amazing things\n"
      ],
      "metadata": {
        "id": "VaibmWbj_H02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setting up Connection to ChatGPT\n",
        "We use something called an API key to talk to ChatGPT, which is a very smart robot that can describe pictures.\n"
      ],
      "metadata": {
        "id": "JDxYvTxGEaFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# OpenAI API Key\n",
        "client = OpenAI(\n",
        "    api_key=\"YOUR API KEY HERE\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "TwoQ_-uTElyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Taking a Screenshot\n",
        "This part is like telling your computer to take a picture of what's on the screen and save it."
      ],
      "metadata": {
        "id": "P0WSO8sO_7m0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function named 'capture_screenshot'. This is a set of instructions for the computer.\n",
        "def capture_screenshot():\n",
        "    # Use the pyautogui tool to take a screenshot. It's like telling your computer to take a picture of the screen.\n",
        "    screenshot = pyautogui.screenshot()\n",
        "\n",
        "    # Save the screenshot as a file named 'screenshot.png'. It's like saving the picture in your computer's memory.\n",
        "    screenshot.save('screenshot.png')\n",
        "\n",
        "    # The function then gives back the name of the file where the screenshot was saved.\n",
        "    return 'screenshot.png'\n"
      ],
      "metadata": {
        "id": "BzPByxl8ACu1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Converting the Image\n",
        "Here, we turn the screenshot into a special code that we can send over the internet."
      ],
      "metadata": {
        "id": "AQuwM9KQAdLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function named 'encode_image'. This function is for turning an image into a special code.\n",
        "def encode_image(image_path):\n",
        "    # Open the image file at the given path ('image_path').\n",
        "    # 'rb' means read the file in binary mode, which is the way computers read files.\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        # Convert the image file to base64 code. This is like translating the image into a secret language.\n",
        "        # Then, decode this code into a string format that can be easily used and sent over the internet.\n",
        "        return base64.b64encode(image_file.read()).decode('utf-8')\n"
      ],
      "metadata": {
        "id": "hi_74oxqArmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Asking ChatGPT about the Image:\n",
        "We send the image to ChatGPT and ask, \"What's in this image?\" ChatGPT looks at the image and gives us an answer."
      ],
      "metadata": {
        "id": "MwC4gKfDA538"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function named 'analyze_image' for analyzing the content of an image.\n",
        "def analyze_image(image_path):\n",
        "    # First, convert the image at the given path to base64 format using the 'encode_image' function we defined earlier.\n",
        "    base64_image = encode_image(image_path)\n",
        "\n",
        "    # Send a request to the OpenAI's ChatGPT model to analyze the image.\n",
        "    # This is like asking a very smart robot to look at the image and tell us what it sees.\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4-vision-preview\",  # Specify the model to use, here it's GPT-4 optimized for analyzing images.\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",  # This is a system message that sets up the context for the analysis.\n",
        "                \"content\": \"\"\"\n",
        "                            Whats in this image?\n",
        "                            \"\"\",  # The question we are asking about the image.\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",  # This represents the user's input.\n",
        "                \"content\": [\n",
        "                    # Provide the image in base64 format as a URL. This is how we show the image to the model.\n",
        "                    {\"type\": \"image_url\", \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
        "                ],\n",
        "            },\n",
        "        ],\n",
        "        max_tokens=500,  # This sets a limit on how long the response from the model can be.\n",
        "    )\n",
        "\n",
        "    # Get the response from the model. This is what the model thinks is in the image.\n",
        "    response_text = response.choices[0].message.content\n",
        "\n",
        "    # Return the response text. This is the model's description of the image.\n",
        "    return response_text\n"
      ],
      "metadata": {
        "id": "JV1jNQ5bBEqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reading Out Loud:\n",
        "This is where the computer reads out what ChatGPT said about the image. It's like having a friend who can describe things to you."
      ],
      "metadata": {
        "id": "rdvLvD5JBjtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function called 'narrate_text'. This function is used to make the computer speak out loud.\n",
        "def narrate_text(text):\n",
        "    # Initialize the text-to-speech engine. This is like starting up the tool that will read the text out loud.\n",
        "    engine = pyttsx3.init()\n",
        "\n",
        "    # Tell the text-to-speech engine to say the provided text. It's like giving it a script to read.\n",
        "    engine.say(text)\n",
        "\n",
        "    # Make the program wait until the text-to-speech engine has finished speaking.\n",
        "    # This ensures that the computer doesn't move on to do something else before finishing speaking.\n",
        "    engine.runAndWait()\n"
      ],
      "metadata": {
        "id": "vEic7-3nCLtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Listening to Your Voice:\n",
        " Here, the computer listens to what you say. You need to press and hold the 'shift' key and then speak."
      ],
      "metadata": {
        "id": "DA0-Cn6ICekY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function called 'get_voice_input' to listen to and recognize spoken words.\n",
        "def get_voice_input():\n",
        "    # Create a speech recognizer. This is like giving your computer the ability to understand spoken language.\n",
        "    recognizer = sr.Recognizer()\n",
        "\n",
        "    # Start using the computer's microphone as the source of audio.\n",
        "    with sr.Microphone() as source:\n",
        "        # Print a message to let the user know that the computer is ready to listen.\n",
        "        print(\"Listening... Press and hold a key to speak.\")\n",
        "\n",
        "        # Set how long the recognizer waits after the speaker stops talking before it considers the speech complete.\n",
        "        recognizer.pause_threshold = 0.5  # waits for half a second of silence before ending\n",
        "\n",
        "        # Wait for the user to press the 'shift' key to start speaking. This is like a 'start talking' button.\n",
        "        keyboard.wait('shift')\n",
        "\n",
        "        # Listen for the audio (speech) from the microphone.\n",
        "        audio = recognizer.listen(source, timeout=None, phrase_time_limit=None)\n",
        "\n",
        "        # Print a message to let the user know that the speech is being processed.\n",
        "        print(\"Processing...\")\n",
        "\n",
        "    # Try to recognize what was said using Google's speech recognition service.\n",
        "    try:\n",
        "        return recognizer.recognize_google(audio)\n",
        "    except sr.UnknownValueError:\n",
        "        # If the speech was unclear, return a message saying it couldn't understand the audio.\n",
        "        return \"Could not understand audio\"\n",
        "    except sr.RequestError:\n",
        "        # If there's a problem with the internet connection, return a message to check the connection.\n",
        "        return \"Could not request results; check your internet connection\"\n"
      ],
      "metadata": {
        "id": "2i7qT9muC367"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Putting It All Together:\n",
        "This is where everything comes together. The computer keeps listening to you. When you speak, it takes a screenshot, asks ChatGPT about it, and then reads the description back to you."
      ],
      "metadata": {
        "id": "ZsKzmoo6DJpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the main function that orchestrates the other functions in the program.\n",
        "def main():\n",
        "    try:\n",
        "        # Start an infinite loop. This means the program will keep running until we tell it to stop.\n",
        "        while True:\n",
        "            # Get a voice command from the user and convert it to lowercase.\n",
        "            command = get_voice_input().lower()\n",
        "\n",
        "            # Check if the command is to exit or quit the program.\n",
        "            if 'exit' in command or 'quit' in command:\n",
        "                break  # If the command is to exit or quit, break out of the loop and end the program.\n",
        "            else:\n",
        "                # If the command is not to exit, then take a screenshot.\n",
        "                image_path = capture_screenshot()\n",
        "\n",
        "                # Analyze the screenshot and get a description of it.\n",
        "                description = analyze_image(image_path)\n",
        "\n",
        "                # Read out the description using the text-to-speech function.\n",
        "                narrate_text(description)\n",
        "    except KeyboardInterrupt:\n",
        "        # If there is a keyboard interrupt (like pressing Ctrl+C), pass and do nothing.\n",
        "        pass\n",
        "\n",
        "# Check if this script is being run directly (and not being imported elsewhere).\n",
        "if __name__ == '__main__':\n",
        "    # If the script is being run directly, call the main function to start the program.\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "fd_p2b_gD0J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###NOTE**::\n",
        "Be Patient:\n",
        "Sometimes, the computer might not understand you, or the internet might be slow. Just try again."
      ],
      "metadata": {
        "id": "pf83wokXDWIX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "That's pretty much it! You've got a smart helper right in your computer that can see and speak, thanks to this program. Isn't technology amazing? ðŸŒŸ"
      ],
      "metadata": {
        "id": "0svvqsrcD-5q"
      }
    }
  ]
}